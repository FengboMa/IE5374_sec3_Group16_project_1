---
title: "IE 5374 Project - Sec3 - Group16 1"
author: "Fengbo Ma Ankita Yadav Zeeshan Ali Shaikh"
date: "10/12/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
toc: yes
toc_float: yes
---

# IE 5374 Foundations of Data Analytics
# Project 1


## Project proposal
The group obtained numbers of data sets about January and February flight information for the years 2019 and 2020. The open sources data sets were provided by the Bureau of Transportation Statistics, Govt. of the USA. The group was managed to provide reasonable analytics and visualizations based on business questions that stockholders might pay special attention to. The group performed a series of analyses on the messy, complex, and real-life air-line data set obtained from the source mentioned above and combined them together in order to visualize it. The group mapped and converted the relevant information into a single data set.

The final data set will be more reliable, organized, convenient to use that include information about origin airport, destination airport, airplane information, departure time and arrival time, etc.

## Data Acquisition


## Data Wrangling 

```{r include = FALSE, message = FALSE, warning = FALSE, cache = TRUE}
library(tidyr)
library(dplyr)  
library(magrittr)
library(stringr)
library(lubridate)
library(lemon)
library(knitr)
library(ggplot2)
library(gridExtra)
library(tidyverse)
```
### Discovering 

####import data
```{r message = FALSE, warning = FALSE, cache = TRUE}
#import data for Jan 2019
df119 = read_csv("Jan_2019_ontime.csv")

#import data for Jan 2020
df120 = read_csv("Jan_2020_ontime.csv")

#import data for Feb 2019
df219 = read_csv("Feb_2019_ontime.csv")

#import data for Feb 2020
df220 = read_csv("Feb_2020_ontime.csv")

#import data frame about air carrier name
dfc = read_csv("IATA Code.csv")

#import data indicating brand code share partners for air carriers
dfbcp = read_csv("BrandedCodesharePartners.csv")

```
#### Summary Statisics 

In this section, we check all the column names in the four data frames, from which we are extracting the unique carrier id of flights and checking whether the data frames consist of NA values, and displaying the number of NA values in each column.
```{r message = FALSE, warning = FALSE, cache = TRUE}
#display colume name for all the data frame
colnames(df119)
colnames(df120)
colnames(df219)
colnames(df220)

#display all the air carrier name in the data frame
unique (df119$OP_UNIQUE_CARRIER)
unique (df120$OP_UNIQUE_CARRIER)
unique (df219$OP_UNIQUE_CARRIER)
unique (df220$OP_UNIQUE_CARRIER)

#first time checking for NA variable
kable(
  df119 %>%
    summarise_all(funs(sum(is.na(.))))
,caption="Check for NA January 2019")

kable(
  df120 %>%
    summarise_all(funs(sum(is.na(.))))
  ,caption="Check for NA January 2020")

kable(  
  df219 %>%
    summarise_all(funs(sum(is.na(.))))
,caption="Check for NA February 2019")

kable(    
  df220 %>%
    summarise_all(funs(sum(is.na(.))))
,caption="Check for NA February 2020")



#NA number exist for all data frames
```
#### Discovering Discrete Data

```{r message = FALSE, warning = FALSE, cache = TRUE}

# count for max number row in the data set using summarize function rather than dimension function
# Summarize function provide only one out out that we need

kable(
  df119 %>% 
    summarize(DAY_OF_MONTH=n()),
caption="Number of rows in January 2019 dataset")

kable(
  df120 %>% 
    summarize(DAY_OF_MONTH=n()),
caption="Number of rows in January 2020 dataset")


kable(
  df219 %>% 
    summarize(DAY_OF_MONTH=n()),
caption="Number of rows in February 2019 dataset")


kable(
  df220 %>% 
    summarize(DAY_OF_MONTH=n()),
caption="Number of rows in February 2020 dataset")


```
#### Data discovering using visualizations
Displaying the total number of flights using the bar chart for all 30 days for January 2019, January 2020, February 2019, and February 2020.

```{r message = FALSE, warning = FALSE, cache = TRUE}
#Data discovering using visualizations
#Display number of flight in each day

# plot line chart for Jan 2019 
df119 %>% 
  count(DAY_OF_MONTH) %>% 
  ggplot(aes(x=DAY_OF_MONTH, y=n)) + 
  geom_line(stat = "identity") +
  ggtitle("January 2019 Date vs. Number of Flights")+
  geom_point()+
  expand_limits(y=0)+
  labs(x="Date (Day)", y="Number of Flights")

# plot line chart for Feb 2019   
df120 %>% 
  count(DAY_OF_MONTH) %>% 
  ggplot(aes(x=DAY_OF_MONTH, y=n)) + 
  geom_line(stat = "identity") +
  ggtitle("January 2020 Date vs. Number of Flights")+
  geom_point()+
  expand_limits(y=0)+
  labs(x="Date (Day)", y="Number of Flights") 

# plot line chart for Jan 2020 
df219 %>% 
  count(DAY_OF_MONTH) %>% 
  ggplot(aes(x=DAY_OF_MONTH, y=n)) + 
  geom_line(stat = "identity") +
  ggtitle("February 2019 Date vs. Number of Flights")+
  geom_point()+
  expand_limits(y=0)+
  labs(x="Date (Day)", y="Number of Flights")

# plot line chart for Feb 2020 
df220 %>% 
  count(DAY_OF_MONTH) %>% 
  ggplot(aes(x=DAY_OF_MONTH, y=n)) + 
  geom_line(stat = "identity") +
  ggtitle("February 2020 Date vs. Number of Flights")+
  geom_point()+
  expand_limits(y=0)+
  labs(x="Date (Day)", y="Number of Flights")
```


### Structuring 

#### Convert String to Dates (date change)

Earlier we had a separate date, month and no year specified, so we made a new column known as Day.of.month which displays the entire date.

```{r message = FALSE, warning = FALSE, cache = TRUE}
#In original data sets, dates are not in date format
#converting everything into date using function as.Date

#Converting for Jan 2019
df119 = df119 %>%
  mutate(df119,Day.of.month = paste(Year="2019", Month="01", DAY_OF_MONTH, sep = "-"))
df119$Day.of.month = as.Date(df119$Day.of.month)

#Converting for Jan 2019
df120 = df120 %>%
  mutate(df120,Day.of.month = paste(Year="2020", Month="01", DAY_OF_MONTH, sep = "-"))
df120$Day.of.month = as.Date(df120$Day.of.month)

#Converting for Jan 2019
df219 = df219 %>%
  mutate(df219,Day.of.month = paste(Year="2019", Month="02", DAY_OF_MONTH, sep = "-"))
df219$Day.of.month = as.Date(df219$Day.of.month)

#Converting for Jan 2019
df220 = df220 %>%
  mutate(df220,Day.of.month = paste(Year="2020", Month="02", DAY_OF_MONTH, sep = "-"))
df220$Day.of.month = as.Date(df220$Day.of.month)
```

#### time format change

In the original data set the time formatting was not correct, so we altered the formatting to put it into a standard format for both arrival and departure time.

```{r message = FALSE, warning = FALSE, cache = TRUE}
# Converting for Jan 2019
df119 = df119 %>% 
  mutate(
    Arr.time = format(strptime(sprintf('%04d',as.integer(ARR_TIME)), format='%H%M'), '%H:%M'),
    Dep.time = format(strptime(sprintf('%04d',as.integer(DEP_TIME)), format='%H%M'), '%H:%M')
        )
#Converting for Feb 2019
df120 = df120 %>%
  mutate(
    Arr.time = format(strptime(sprintf('%04d',as.integer(ARR_TIME)), format='%H%M'), '%H:%M'),
    Dep.time = format(strptime(sprintf('%04d',as.integer(DEP_TIME)), format='%H%M'), '%H:%M')
        )
#Converting for Jan 2020
df219 = df219 %>%
  mutate(
    Arr.time = format(strptime(sprintf('%04d',as.integer(ARR_TIME)), format='%H%M'), '%H:%M'),
    Dep.time = format(strptime(sprintf('%04d',as.integer(DEP_TIME)), format='%H%M'), '%H:%M')
        )
#Converting for Feb 2020
df220 = df220 %>%
  mutate(
    Arr.time = format(strptime(sprintf('%04d',as.integer(ARR_TIME)), format='%H%M'), '%H:%M'),
    Dep.time = format(strptime(sprintf('%04d',as.integer(DEP_TIME)), format='%H%M'), '%H:%M')
        )
```

#### Creating Categories from continous Data (Weekday change)

In this section, we converted the day of week from numeric character to the day of the week, which it represented.

```{r message = FALSE, warning = FALSE, cache = TRUE}
# weekday was shown as  integers where 1 as Monday and 7 as Sunday
#In this section, replace everything from a number to words

#replacing for the Jan 2019 data sets
df119 <- df119 %>% 
  mutate(Day.of.week  = wday(Day.of.month,label=TRUE,abbr = FALSE)
  )

#replacing for the Jan 2020 data sets
df120 <- df120 %>% 
  mutate(Day.of.week = wday(Day.of.month,label=TRUE,abbr = FALSE)
  )

#replacing for the Feb 2019 data sets
df219 <- df219 %>% 
  mutate(Day.of.week = wday(Day.of.month,label=TRUE,abbr = FALSE)
  )

#replacing for the Feb 2020 data sets
df220 <- df220 %>% 
  mutate(Day.of.week = wday(Day.of.month,label=TRUE,abbr = FALSE)
  )
```

#### Combine Text Column (Merging)

In this section we are merging data from ,OP_UNIQUE_CARRIER and OP_CARRIER_FL_NUM creating a new column called Flight Number.

```{r message = FALSE, warning = FALSE, cache = TRUE}
#Combine two column to form a new information

#Combine for Jan 2019 data set
df119 = df119 %>% 
  unite('Flight Number',OP_UNIQUE_CARRIER,OP_CARRIER_FL_NUM,remove=FALSE,sep="-")

#Combine for Jan 2020 data set
df120 = df120 %>% 
  unite('Flight Number',OP_UNIQUE_CARRIER,OP_CARRIER_FL_NUM,remove=FALSE,sep="-")

#Combine for Feb 2019 data set
df219 = df219 %>% 
  unite('Flight Number',OP_UNIQUE_CARRIER,OP_CARRIER_FL_NUM,remove=FALSE,sep="-")

#Combine for Feb 2020 data set
df220 = df220 %>% 
  unite('Flight Number',OP_UNIQUE_CARRIER,OP_CARRIER_FL_NUM,remove=FALSE,sep="-")
```

### Cleaning

#### Remove NA (Fix missing data)

In our data sets, we had the last column filled with NA's, so we removed them and checked again whether there is any NA's left or not, in the other half of the code, we replaced all the NA's by ‘0’ so that we don’t lose our data from the data set. At the end of this section, we have displayed the result of values with no NA`s in the data set.

```{r message = FALSE, warning = FALSE, cache = TRUE}
#Remove NAs

df119 = select(df119,-TAIL_NUM,-...22)
df120 = select(df120,-TAIL_NUM,-...22)
df219 = select(df219,-TAIL_NUM,-...22)
df220 = select(df220,-TAIL_NUM,-...22)

# Checking the NA values for the entire data set.

df119 %>%
  summarise_all(funs(sum(is.na(.))))
df120 %>%
  summarise_all(funs(sum(is.na(.))))
df219 %>%
  summarise_all(funs(sum(is.na(.))))
df220 %>%
  summarise_all(funs(sum(is.na(.))))


# Replacing NA values to 0

df119 <- mutate_at(df119, c("DEP_TIME", "ARR_TIME", "Arr.time", "Dep.time","ARR_DEL15","DEP_DEL15"), ~replace(., is.na(.), 0))

df120 <- mutate_at(df120, c("DEP_TIME", "ARR_TIME", "Arr.time", "Dep.time","ARR_DEL15","DEP_DEL15"), ~replace(., is.na(.), 0))

df219 <- mutate_at(df219, c("DEP_TIME", "ARR_TIME", "Arr.time", "Dep.time","ARR_DEL15","DEP_DEL15"), ~replace(., is.na(.), 0))

df220 <- mutate_at(df220, c("DEP_TIME", "ARR_TIME", "Arr.time", "Dep.time","ARR_DEL15","DEP_DEL15"), ~replace(., is.na(.), 0))

#Validating
kable(
  df119 %>%
    summarise_all(funs(sum(is.na(.)))))

kable(
  df120 %>%
    summarise_all(funs(sum(is.na(.)))))

kable(
  df219 %>%
    summarise_all(funs(sum(is.na(.)))))

kable(
  df220 %>%
    summarise_all(funs(sum(is.na(.)))))
```
#### Check Outliers

In this section we are checking for outliers, so the data set was inconsistent, we first convert the values in minutes, then we filter out the values which are causing errors in making the decisions.

We manage to check outliers by looking at the depart time and arriving time. In the data set there are some outliers such as the duration of the flight is less than 10 minutes. It might either causing by a human error or a emergency call back. Under both situation, it does not help us to do the data driven-decision. Remove outliers for all the datasets rather than fix them. We do not have a fitable prediction model for the task. 

```{r message = FALSE, warning = FALSE, cache = TRUE}
# Adding new column to check for time 
# subtracting arriving time and departing time to find the flight duration
df119$time_check = round(abs(as.double(as.POSIXct(df119$Arr.time, format = "%H:%M")- as.POSIXct(df119$Dep.time, format = "%H:%M"))/3600), digits = 2)

#Filter out any flight shorter than 60min*0.2
df119 = df119 %>% 
  filter(time_check >0.2)

#Display output flight time in hour
kable(
  df119 %>% 
    count(time_check) %>% 
    head(5)
  ,caption = "Flight time check January 2019", col.names = c("Time Check (hours)" , "Number of Flights")
  )

# subtracting arriving time and departing time to find the flight duration
df120$time_check = round(abs(as.double(as.POSIXct(df120$Arr.time, format = "%H:%M")- as.POSIXct(df120$Dep.time, format = "%H:%M"))/3600), digits = 2)

#Filter out any flight shorter than 60min*0.2
df120 = df120 %>% 
  filter(time_check >0.2)

#Display output flight time in hour
kable(
  df120 %>% 
    count(time_check) %>% 
    head(5)
  ,caption = "Flight time check January 2020", col.names = c("Time Check (hours)" , "Number of Flights")
  )

# subtracting arriving time and departing time to find the flight duration
df219$time_check = round(abs(as.double(as.POSIXct(df219$Arr.time, format = "%H:%M")- as.POSIXct(df219$Dep.time, format = "%H:%M"))/3600), digits = 2)

#Filter out any flight shorter than 60min*0.2
df219 = df219 %>% 
  filter(time_check >0.2)

#Display output flight time in hour
kable(
  df219 %>% 
    count(time_check) %>% 
    head(5)
  ,caption = "Flight time check February 2019", col.names = c("Time Check (hours)" , "Number of Flights")
  )

# subtracting arriving time and departing time to find the flight duration
df220$time_check = round(abs(as.double(as.POSIXct(df220$Arr.time, format = "%H:%M")- as.POSIXct(df220$Dep.time, format = "%H:%M"))/3600), digits = 2)

#Filter out any flight shorter than 60min*0.2
df220 = df220 %>% 
  filter(time_check >0.2)

#Display output flight time in hour
kable(
  df220 %>% 
    count(time_check) %>% 
    head(5)
  ,caption = "Flight time check February 2020", col.names = c("Time Check (hours)" , "Number of Flights")
  )

```

### Enriching

#### Add attributes
In this section, we are working on the datasets, where we are joining all the data set of four months data to the dfc dataset, using a common column name.

```{r message = FALSE, warning = FALSE, cache = TRUE}
# Adding extra column by using an additional table
# Giving companies name by using their IATA code

#select useful column for the project
#In this case, get rid og the second column in IATA code dataset
dfc = select(dfc,-2)
colnames(dfc)[1] = "OP_UNIQUE_CARRIER"


#convert everything into upper case to aviod unnecessary chaos
#for example: Southwestern Airline vs. SouthWestern Airline
dfc = dfc %>%
  mutate(`Air Carrier Name`= toupper(`Air Carrier Name`))

#left join and form a new column
df119 = left_join(df119,dfc)
df120 = left_join(df120,dfc)
df219 = left_join(df219,dfc)
df220 = left_join(df220,dfc)
```


#### Add Category
we would like to add a category to each company and group them by their their business partner. Several company share common air routes. In the transportation field, they are so called Branded Code share Partners. Rather than splitting by using if else statement (where we perhapes need to run then thousands of loops with 20 elseif statement), we put everything into another data set and perform a left join. (Due to the limited of our device computational power, we consider it as a good way to get around the memoery restrictions)
```{r message = FALSE, warning = FALSE, cache = TRUE}
#Introducing the new dataset and change col name into a share-in-common name
colnames(dfbcp)[1] = "Air Carrier Name"
dfbcp = dfbcp %>%
  mutate(`Air Carrier Name`= toupper(`Air Carrier Name`))

#left join two data sets
df119 = left_join(df119,dfbcp,by= "Air Carrier Name")
df120 = left_join(df120,dfbcp,by= "Air Carrier Name")
df219 = left_join(df219,dfbcp,by= "Air Carrier Name")
df220 = left_join(df220,dfbcp,by= "Air Carrier Name")
```

### Validating

#### Checking NA value

After joining the datasets there is a possibility that our data set might again have redundancies, so we again check for NA values using the summarize function.

```{r message = FALSE, warning = FALSE, cache = TRUE}
#Re-run NA checks

kable(
  df119 %>%
    summarise_all(funs(sum(is.na(.))))
,caption = "Double check for NA value January 2019")

kable(
  df120 %>%
    summarise_all(funs(sum(is.na(.))))
,caption = "Double check for NA value January 2020")

kable(
  df219 %>%
    summarise_all(funs(sum(is.na(.))))
,caption = "Double check for NA value February 2019")

kable(
  df220 %>%
    summarise_all(funs(sum(is.na(.))))
,caption = "Double check for NA value February 2020")

```
Every data sets do not contain any NA values by now.

#### Checking date type
Double checking data type for dates. Select everything is not in date format.
```{r message = FALSE, warning = FALSE, cache = TRUE}
#Select everything is not in date format.
kable(
  df119 %>% 
    filter(is.Date(Day.of.month)==FALSE) %>%
             select(Day.of.month),
           caption="is.Date() Check for January-2019"
  )

#Select everything is not in date format.
kable(
  df120 %>% 
    filter(is.Date(Day.of.month)==FALSE) %>%
             select(Day.of.month),
           caption="is.Date() Check for January-2020"
  )

#Select everything is not in date format.
kable(
  df219 %>% 
    filter(is.Date(Day.of.month)==FALSE) %>%
             select(Day.of.month),
           caption="is.Date() Check for February-2019"
  )

#Select everything is not in date format.
kable(
  df220 %>% 
    filter(is.Date(Day.of.month)==FALSE) %>%
             select(Day.of.month),
           caption="is.Date() Check for February-2020"
  )
```
Nothing shows up. That means everything is now in date format.

#### Check duplication

There's a possibility that a single carrier with the same flight number/id is flying from similar or different locations, so in this section, we are trying to check for duplication and listing them down, for the same number of flights that are on the same timing, date, and having the same distance.
Check duplication by group by every possible categories. 

```{r message = FALSE, warning = FALSE, cache = TRUE}
#use group by + count to find if everything is duplicate
#Check n for count

#check for Jan 2019

kable(
  df119 %>% 
    group_by(`Flight Number`, Day.of.month, Dep.time, Arr.time, DISTANCE) %>% 
    count(sort = TRUE) %>% 
    head(10)
  ,caption="Duplication Check for January 2019")

#check for Jan 2020
kable(
  df120 %>% 
    group_by(`Flight Number`, Day.of.month, Dep.time, Arr.time, DISTANCE) %>% 
    count(sort = TRUE)%>% 
    head(10)
  ,caption="Duplication Check for January 2020")

#check for Feb 2019
kable(
  df219 %>% 
    group_by(`Flight Number`, Day.of.month, Dep.time, Arr.time, DISTANCE) %>% 
    count(sort = TRUE)%>% 
    head(10)
  ,caption="Duplication Check for February 2019")

#check for Feb 2020
kable(
  df220 %>% 
    group_by(`Flight Number`, Day.of.month, Dep.time, Arr.time, DISTANCE) %>% 
    count(sort = TRUE)%>% 
    head(10)
  ,caption="Duplication Check for February 2020")

```

### Publishing

#### Bind
Creating one large data frame by combining all the four data frames using the rbind function for working on business problems and checking for the NA values again, if any cleaning needs to be done.

```{r message = FALSE, warning = FALSE}
df = rbind(df119, df120,df219,df220)

df %>%
  summarise_all(funs(sum(is.na(.))))
```
#### Publishing Github
The data by know is fully unified. The data set is now cleaned (NA removed and no more ouliers), multiple columns added to the data base and enriched the entire data set.

The progress should be available to others and ready for perform futhur analysis. Since the group do not have access to any Northeastern University code sharing platform, the group decide to push everything to Github as an alternative for publishing the code. 

## Decision-making with data
### 1. Display the total number of unique Air carrier names.
```{r message = FALSE, warning = FALSE, cache = TRUE}
unique_airline = unique(df$`Air Carrier Name`)
unique_airline
total_number = length(unique_airline)
paste("There are total", total_number,"unique Air carriers.")

df %>% 
  count(`Air Carrier Name`) %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-n), y=n,fill= n)) +
  scale_fill_continuous(name = 'Flight Values',labels = scales::label_number_si())+
  geom_bar(stat = "identity") +
  ggtitle("Air carrier company name vs. Total number of flights")+
  labs(x= "Air carrier name", y= "Number of flight")+
  expand_limits(x = c(0, NA), y = c(0,NA)) +
  scale_y_continuous(labels = scales::label_number_si())+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
 
```
It can be depicted that Southwest Airlines has the highest count of flights which is about 400K, whereas Hawaiian Airlines has the least number of flights about 20K. Furthermore, Delta Airlines and American Airlines have the same number of flights around 290K.


### 2. Which day of the week had the most flights? 
```{r message = FALSE, warning = FALSE, cache = TRUE}
kable(
Task2<-
  df%>%
  select(Day.of.week)%>%
  group_by(Day.of.week)%>%
  arrange(Day.of.week, order=TRUE)%>%
  summarise(Flight_count=n()),
  caption = 'Total Flights on Each Day'
)

Task2 %>% 
  ggplot(aes(Flight_count, Day.of.week,))+
  geom_bar(stat= "identity", color="darkblue", fill="lightblue" )

df%>%
  select(Day.of.week)%>%
  group_by(Day.of.week)%>%
  summarise(Flight_count=n())%>%
  arrange(desc(Flight_count))%>%
  slice(1)

```
It can be depicted that Thursday had the highest number of flights which was approximately 366K and is represented in the table, followed by Friday and Wednesday about 350K. On the contrary, Saturday had the least number of flights about 275K.


### 3. Which flight had the largest distance? And was the distance the reason for the delay? And Which flight had the smallest distance and was there a delay?
```{r message = FALSE, warning = FALSE, cache = TRUE}

  max(df$DISTANCE)

df %>% 
  select(DISTANCE, DEP_DEL15) %>% 
  ggplot( aes(x=factor(DEP_DEL15), y=DISTANCE, color=factor(DEP_DEL15), fill=factor(DEP_DEL15))) + 
  geom_point() +
  ggtitle("Relationship between distance and cancelation")+
  labs(x= "Canceled? (0 for NO, 1 for YES)", y= "Distanse (Mile)")+
  theme_minimal()


kable(
  df %>% 
  filter(DEP_DEL15 == 1) %>% 
  summarise(max_distance=max(DISTANCE), min_distance=min(DISTANCE), avg_distance=mean(DISTANCE)), 
  caption="Summary Statistics for Delayed flight"
)


kable(
  df %>% 
  filter(DEP_DEL15 == 0) %>% 
  summarise(max_distance=max(DISTANCE), min_distance=min(DISTANCE), avg_distance=mean(DISTANCE)), 
  caption="Summary Statistics for Non Delayed flight"
)


```

### 4. How many numbers of flights were canceled in week 1? which week had the most flight canceled for both the year?
```{r message = FALSE, warning = FALSE, cache = TRUE}
c <-
  df %>%
  select(Day.of.month,Day.of.week, CANCELLED) %>%
  filter(Day.of.month >= "2019-01-01" & Day.of.month<= "2019-01-07") %>%
  group_by(Day.of.week) %>% 
  summarise(CancelledFlights = n())


kable (c,
       caption="Numbers of flights cancelled in week 1"
)

value = sum(c$CancelledFlights)
paste("The total number of Cancelled Flights in Week 1:", value)
       


kable(
  df%>%
  select(Day.of.week,CANCELLED)%>%
  group_by(Day.of.week)%>%
  arrange(Day.of.week, order=TRUE)%>%
  summarise(Values=n()),
  caption = 'Total Flights for both years grouped by week',
)


kable(
  df%>%
  select(Day.of.week)%>%
  group_by(Day.of.week)%>%
  summarise(Values=n())%>%
  arrange(desc(Values))%>%
  slice(1),
  caption = 'Week that had the most cancelled flights for both years'
)

```
First, we displayed the total number of flights canceled through the four months, in which we found that the total number of flights canceled in week 1 was 134503 and Thursday had the most number of flights canceled which was 366146 flights.

### 5. The average delay rate of each air carrier?
```{r message = FALSE, warning = FALSE, cache = TRUE}
A = df %>% 
  select(`Air Carrier Name`,DEP_DEL15)%>%
  filter(DEP_DEL15 == 1)%>%
  group_by(`Air Carrier Name`)%>%
  summarise(Value=n()) %>%
  arrange(desc(Value)) 

B = df %>% 
  select(`Air Carrier Name`)%>%
  group_by(`Air Carrier Name`)%>%
  summarise(Value1=n()) %>%
  arrange(desc(Value1))

C=left_join(A,B, by= 'Air Carrier Name')

C$`AVERAGE DELAY` = C$Value/C$Value1

colnames(C)[2] = "Delayed Flight"
colnames(C)[3] = "Total flight"

kable(C)
C %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-`AVERAGE DELAY`), y=`AVERAGE DELAY`,fill= `AVERAGE DELAY`))+
  geom_bar(stat = "identity")+
  ggtitle("Average Delays of the FLight")+
  labs(x= "Air Carriers", y= "Average Delay")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, ))+
  theme(plot.margin=unit(c(1,1,1.5,1.2),"cm"))
  
  
C%>%
  ggplot( aes(x = "", y = `AVERAGE DELAY`, fill = `AVERAGE DELAY`)) +
  geom_col(color = "black") +
   geom_label(aes(label = `AVERAGE DELAY`),
              position = position_stack(vjust = 1),
             size=2,
             color = "white",
            show.legend = FALSE) +
  coord_polar(theta = "y")+
ggtitle("Representation in Pie Chart")
```
### 6. Which Branded Codeshare Partners has the most flights in the given four months.
```{r message = FALSE, warning = FALSE, cache = TRUE}
df%>%
  select(`Air Carrier Name`, `Codeshare Partner`)%>%
  group_by(`Codeshare Partner`)%>%
  summarise(Value1=n()) %>%
  arrange(desc(Value1))%>%
  slice(1)
```

### 7. At which destination with the airport id had the most flight canceled? – least – comparison graphs
```{r message = FALSE, warning = FALSE, cache = TRUE}
kable(
  df%>%
  select(DEST_AIRPORT_ID,CANCELLED)%>%
  group_by(DEST_AIRPORT_ID)%>%
  arrange(DEST_AIRPORT_ID, order=TRUE)%>%
  summarise(Value=n()) %>% 
  slice(1),
  caption = 'the airport id which had the most flight cancelled',
)
```
The airport id 10135 had the greatest number of flights canceled which was 1472.

### 8. At which destination had the most flight delays and the most flight diverted? – least
```{r message = FALSE, warning = FALSE}
plot81 = 
df %>% 
  filter (DEP_DEL15 == 1) %>% 
  count(DEST, sort=TRUE) %>% 
  slice (1:5) %>% 
  ggplot(aes(x=reorder(DEST,-n), y=n, fill= DEST, label= n)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("ORD" = "#EAD1DC","ATL" = "#FCE5CD","DFW" = "#FFF2CC","CLT"="#D9EAD3","LGA"="#D0E0E3"))+
  ggtitle("Top 5 Airport with the most delays")+
  labs(x= "Airport", y= "Number of delay")+
  geom_text(aes(label=n), position=position_dodge(width=0.9), vjust=1.25)

plot82 =
df %>% 
  filter (DEP_DEL15 == 0) %>% 
  count(DEST, sort=TRUE) %>% 
  tail(n=5) %>% 
  ggplot(aes(x=reorder(DEST,-n), y=n, fill= DEST, label= n)) + 
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("OGD" = "#cfe2f3","HGR" = "#b2cce4","OWB" = "#fff2cc","DDC"="#d0e0e3","BFM"="#ffe599"))+
  ggtitle("Bottom 5 Airport with the most delays")+
  labs(x= "Airport", y= "Number of delays")+
  geom_text(aes(label=n), position=position_dodge(width=0.9), vjust=1.25)

plot83 =
df %>% 
  filter (DIVERTED == 0) %>% 
  count(DEST, sort=TRUE) %>% 
  slice (1:5)  %>% 
  ggplot(aes(x=reorder(DEST,-n), y=n, fill= DEST, label= n)) + 
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("ATL" = "#d5d1ea","ORD" = "#e2d1ea","DFW" = "#ffe0f9","CLT"="#fccdd9","DEN"="#fccdcd"))+
  ggtitle("Bottom 5 Airport with the most delays")+
  ggtitle("Top 5 Airport with the most diverte")+
  labs(x= "Airport", y= "Number of diverted")+
  geom_text(aes(label=n), position=position_dodge(width=0.9), vjust=1.25)

plot84 =
df %>% 
  filter (DIVERTED == 0) %>% 
  count(DEST, sort=TRUE) %>% 
  tail(n=5) %>% 
  ggplot(aes(x=reorder(DEST,-n), y=n, fill= DEST, label= n)) + 
  geom_bar(stat = "identity") +
  ggtitle("Bottom 5 Airport with the most diverte")+
  scale_fill_manual(values = c("OWB" = "#f7c0ec","OGD" = "#e3bfec","ADK" = "#cfbfeb","DDC"="#bbbeeb","BFM"="#a7bdea"))+
  labs(x= "Airport", y= "Number of diverted")+
  geom_text(aes(label=n), position=position_dodge(width=0.9), vjust=1.25)

grid.arrange(plot81,plot82)
grid.arrange(plot83,plot84)
```

### 9. The carrier performance in 2019 vs 2020, analyzing the delay rate for the best top 5 carriers and the worst 5 carriers in both years
```{r message = FALSE, warning = FALSE, cache = TRUE}
DE20191 = df %>% 
  filter(Day.of.month >= "2019-01-01" & Day.of.month<= "2019-02-28") %>% 
  select(`Air Carrier Name`,DEP_DEL15)%>%
  filter(DEP_DEL15 == 1)%>%
  group_by(`Air Carrier Name`)%>%
  summarise(Value=n()) %>%
  arrange(desc(Value)) 

DE20192 = df %>% 
  select(`Air Carrier Name`)%>%
  group_by(`Air Carrier Name`)%>%
  summarise(Value1=n()) %>%
  arrange(desc(Value1))

DE2019=left_join(DE20191,DE20192, by= 'Air Carrier Name')

DE2019$`AVERAGE DELAY` = DE2019$Value/DE2019$Value1

colnames(DE2019)[2] = "Delayed Flight"
colnames(DE2019)[3] = "Total flight"

DE2019 %>% 
  arrange(desc(`AVERAGE DELAY`)) %>% 
  top_n(5) %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-`AVERAGE DELAY`), y=`AVERAGE DELAY`, color=`AVERAGE DELAY`, fill=`AVERAGE DELAY`)) + 
  geom_bar(stat = "identity") +
  ggtitle("Top 5 Air carrier company with the highest delay rate in 2019")+
  labs(x= "Air carrier", y= "delay rate")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

DE2019 %>% 
  arrange(desc(`AVERAGE DELAY`)) %>% 
  tail(n=5) %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-`AVERAGE DELAY`), y=`AVERAGE DELAY`, color=`AVERAGE DELAY`, fill=`AVERAGE DELAY`)) + 
  geom_bar(stat = "identity") +
  ggtitle("Top 5 Air carrier company with the lowest delay rate in 2019")+
  labs(x= "Air carrier", y= "delay rate")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


DE20201 = df %>% 
  filter(Day.of.month >= "2020-01-01" & Day.of.month<= "2020-02-29") %>% 
  select(`Air Carrier Name`,DEP_DEL15)%>%
  filter(DEP_DEL15 == 1)%>%
  group_by(`Air Carrier Name`)%>%
  summarise(Value=n()) %>%
  arrange(desc(Value)) 

DE20202 = df %>% 
  select(`Air Carrier Name`)%>%
  group_by(`Air Carrier Name`)%>%
  summarise(Value1=n()) %>%
  arrange(desc(Value1))

DE2020=left_join(DE20201,DE20202, by= 'Air Carrier Name')

DE2020$`AVERAGE DELAY2` = DE2020$Value/DE2020$Value1

colnames(DE2020)[2] = "Delayed Flight2"
colnames(DE2020)[3] = "Total flight2"

DE2019 %>% 
  arrange(desc(`AVERAGE DELAY`)) %>% 
  tail(n=5) %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-`AVERAGE DELAY`), y=`AVERAGE DELAY`, color=`AVERAGE DELAY`, fill=`AVERAGE DELAY`)) + 
  geom_bar(stat = "identity") +
  ggtitle("Top 5 Air carrier company with the lowest delay rate in 2019")+
  labs(x= "Air carrier", y= "delay rate")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

DE2020 %>% 
  arrange(desc(`AVERAGE DELAY2`)) %>% 
  top_n(5) %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-`AVERAGE DELAY2`), y=`AVERAGE DELAY2`, color=`AVERAGE DELAY2`, fill=`AVERAGE DELAY2`)) + 
  geom_bar(stat = "identity") +
  ggtitle("Top 5 Air carrier company with the highest delay rate in 2020")+
  labs(x= "Air carrier", y= "delay rate")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


DE = left_join(DE2019, DE2020)
DE$`delay rate change` = DE$`AVERAGE DELAY2`-DE$`AVERAGE DELAY`

DE %>% 
  select(`Air Carrier Name`,`delay rate change`) %>% 
  ggplot(aes(x=reorder(`Air Carrier Name`,-`delay rate change`), y=`delay rate change`, color=`delay rate change`, fill=`delay rate change`)) + 
  geom_bar(stat = "identity") +
  ggtitle("Change in delay rate for all Air carrier companybetween 2019 to 2020")+
  labs(x= "Air carrier", y= "delay rate change")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

## Conclusion
